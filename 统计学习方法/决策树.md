## 决策树
1. 剪枝是因为学习了错误的训练数据吗？
   如果 a 是对的 b是错的。那学习谁

2. 损失函数：正则化的极大似然函数

决策树分为三个步骤：特征选择，决策树的生成，决策树剪枝。


信息增益方法存在一个缺点：倾向于选择取值多的属性，因为取值越多，
每个子集合的纯度就越好，这就导致信息增益越大。
为了改善这个问题，C4.5算法采用”增益率“择优划分

决策树的基本思想，是对特征空间的划分

### CART剪枝
剪枝的目的：增强泛化性能，这是大前提。
怎么剪，预剪枝，后剪枝。CART是后剪枝。
怎么后剪枝：得到原树，每个结点都减一遍，哪个在验证集上表现好就用哪个。
缺点：慢
怎么提高速度：把子树分类，同一类的一次全剪了。这就是CART的剪枝算法思想。








参考：
1.[cart树怎么进行剪枝？](https://www.zhihu.com/question/22697086)